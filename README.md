Documenta√ß√£o Completa do Pipeline: Feature GenesisEste documento combina a descri√ß√£o detalhada do pipeline de sele√ß√£o de features com a auditoria t√©cnica do c√≥digo, abordando as preocupa√ß√µes de pesquisa quantitativa.Parte 1: Descri√ß√£o do Pipeline de Sele√ß√£o de FeaturesO pipeline Feature Genesis √© um processo robusto e multif√°sico desenhado para transformar um vasto conjunto de dados de s√©ries temporais financeiras em um subconjunto otimizado de features preditivas. O objetivo √© preparar os dados para um modelo de machine learning, garantindo que as features finais sejam informativas, estacion√°rias e n√£o redundantes.O processo ocorre na seguinte ordem:Passo 1: Carregamento e Prepara√ß√£o do Dataset RicoPonto de Partida: O pipeline n√£o come√ßa com dados brutos, mas sim com um dataset j√° enriquecido para 11 pares de moedas (EURUSD, GBPUSD, USDJPY, AUDUSD, USDCAD, EURGBP, EURJPY, GBPJPY, CHFJPY, NZDUSD, XAUUSD).Conte√∫do: Para cada par, o dataset cont√©m mais de 480 colunas, abrangendo:Microestrutura de Mercado: M√©tricas de Order Flow Imbalance (OFI), volatilidade realizada, liquidez, etc.An√°lise T√©cnica Cl√°ssica: Indicadores como RSI, MACD, Bandas de Bollinger em m√∫ltiplos timeframes.Drivers de Rela√ß√µes Intermercado: O pipeline √© alimentado por um conjunto sofisticado de features que capturam a din√¢mica entre as moedas e outros mercados financeiros. Estes n√£o s√£o indicadores gen√©ricos, mas sim m√©tricas calculadas que refletem as rela√ß√µes de correla√ß√£o, beta (sensibilidade) e fluxos entre:Moedas vs. DXY (√çndice do D√≥lar): Mede a for√ßa relativa do par contra o d√≥lar.Moedas vs. Commodities: Como o par se comporta em rela√ß√£o ao petr√≥leo (Brent).Moedas vs. √çndices de A√ß√µes: Rela√ß√£o com o S&P 500 (SPX).Moedas vs. T√≠tulos de D√≠vida: An√°lise dos diferenciais de retorno entre t√≠tulos de d√≠vida dos EUA, Alemanha (DE) e Reino Unido (UK).Ouro (XAU) vs. Juros Reais: Um proxy para o yield real do ouro, um importante driver de sentimento de risco.Passo 2: Transforma√ß√£o para Estacionariedade (Diferencia√ß√£o Fracion√°ria)O Problema: S√©ries temporais financeiras s√£o "n√£o-estacion√°rias", o que as torna imprevis√≠veis para modelos de ML.A Solu√ß√£o: Aplicamos a Diferencia√ß√£o Fracion√°ria, que remove apenas a quantidade de mem√≥ria estritamente necess√°ria para tornar a s√©rie estacion√°ria, preservando ao m√°ximo a informa√ß√£o preditiva.Resultado: Novas features (ex: close_fracdiff_0.5) que s√£o estatisticamente mais est√°veis.Passo 3: Modelagem da Volatilidade (GARCH)O Problema: A volatilidade do mercado n√£o √© constante. Prever a volatilidade futura √© uma feature poderosa.A Solu√ß√£o: Ajustamos um modelo GARCH que aprende com a volatilidade passada para prever a do pr√≥ximo per√≠odo.Resultado: Uma nova feature preditiva: a previs√£o de volatilidade condicional.Passo 4: Decomposi√ß√£o de Sinais (EMD)O Problema: O movimento do pre√ßo √© uma mistura de m√∫ltiplos ciclos e tend√™ncias em diferentes velocidades.A Solu√ß√£o: Aplicamos a Decomposi√ß√£o Emp√≠rica de Modos (EMD) para separar o sinal de pre√ßo em suas ondas constituintes, as Fun√ß√µes de Modo Intr√≠nseco (IMFs).Resultado: Novas features (IMF_1, IMF_2, ...), onde cada uma representa um ciclo de mercado, tornando os padr√µes mais f√°ceis de serem detectados.Passo 5: Teste de Estacionariedade (ADF)O Problema: Precisamos garantir que as transforma√ß√µes funcionaram.A Solu√ß√£o: Aplicamos o teste Augmented Dickey-Fuller (ADF) em todas as features candidatas.Resultado: Apenas as features estatisticamente est√°veis avan√ßam.Passo 6: An√°lise de Redund√¢ncia e ColinearidadeO Problema: Muitas features podem conter a mesma informa√ß√£o (serem redundantes).A Solu√ß√£o: Realizamos uma filtragem em tr√™s etapas:Correla√ß√£o √† Dist√¢ncia (dCor): Captura rela√ß√µes n√£o-lineares para rankear a depend√™ncia.Fator de Infla√ß√£o de Vari√¢ncia (VIF): Remove features que s√£o combina√ß√µes lineares de outras.Informa√ß√£o M√∫tua (MI): Agrupa features com a mesma informa√ß√£o; apenas a mais representativa de cada grupo √© mantida.Resultado: Um conjunto de features menor, onde cada uma contribui com informa√ß√£o √∫nica.Passo 7: Sele√ß√£o Final por Import√¢ncia (CatBoost)O Problema: Precisamos saber quais das features restantes s√£o as mais preditivas.A Solu√ß√£o: Usamos um modelo CatBoost como um "juiz final", treinando-o para prever um alvo (ex: retorno futuro) e avaliando a contribui√ß√£o de cada feature.Resultado: Um ranking final de features baseado na sua import√¢ncia preditiva. Selecionamos o "top N" para formar o conjunto final.Parte 2: Detalhes da Implementa√ß√£o T√©cnicaFluxo de Orquestra√ß√£o: O data_processor.py executa os "motores" de processamento em sequ√™ncia (EMD ‚Üí Stationarization ‚Üí GARCH ‚Üí StatisticalTests). A sele√ß√£o principal ocorre dentro do StatisticalTests nos est√°gios: dCor (ranking) ‚Üí VIF ‚Üí MI ‚Üí Embedded (CatBoost).Implementa√ß√£o do CatBoost (Stage 3): O cora√ß√£o da sele√ß√£o est√° em features/statistical_tests/feature_selection.py::_stage3_selectfrommodel. Ele utiliza CatBoostClassifier ou Regressor com task_type='GPU', aproveitando a acelera√ß√£o de hardware. A valida√ß√£o cruzada para early stopping e agrega√ß√£o de import√¢ncias √© feita com TimeSeriesSplit.Configura√ß√£o e Execu√ß√£o em GPU: A configura√ß√£o √© centralizada em unified_config.py. O pipeline √© projetado para ser GPU-first, com force_gpu_usage=True e gpu_fallback_enabled=False, garantindo performance. O Dask-CUDA gerencia os workers, mapeando uma GPU para cada um.Gera√ß√£o de Logs e Artefatos: O sistema de logging √© robusto, com sa√≠das para o console e para um arquivo JSON (pipeline_execution.log). Durante a sele√ß√£o com CatBoost, s√£o registrados o tamanho do dataset, a configura√ß√£o do modelo, m√©tricas de valida√ß√£o (Accuracy, F1, R¬≤, etc.) e as import√¢ncias das features. Artefatos detalhados s√£o salvos em artifacts/<pair>/stat_tests_selection.json.Prote√ß√£o contra Data Leakage: M√∫ltiplas camadas de prote√ß√£o s√£o implementadas:Gating por Configura√ß√£o: Features com prefixos de "alvo" (ex: y_ret_fwd_) s√£o removidas no in√≠cio.Bloqueio nos Est√°gios: Os est√°gios de VIF e MI t√™m checagens expl√≠citas para bloquear colunas proibidas.Valida√ß√£o Temporal: TimeSeriesSplit √© usado para garantir que o treino sempre ocorra antes da valida√ß√£o.CPCV: Uma implementa√ß√£o de CombinatorialPurgedCrossValidation (padr√£o-ouro para finan√ßas) est√° dispon√≠vel no c√≥digo (cpcv.py), pronta para ser integrada no caminho principal.Parte 3: Auditoria Final, Veredito e Pr√≥ximos PassosVeredito da Implementa√ß√£o AtualO pipeline de sele√ß√£o de features est√° em um estado avan√ßado e robusto. A an√°lise cr√≠tica externa, que apontou a alta qualidade da implementa√ß√£o, est√° correta. O c√≥digo-fonte atual implementa corretamente v√°rias t√©cnicas de ponta em finan√ßas quantitativas, invalidando preocupa√ß√µes baseadas em vers√µes anteriores do c√≥digo.Pontos Fortes Confirmados no C√≥digo:‚úÖ Valida√ß√£o Cruzada Robusta: Uso de CombinatorialPurgedCrossValidation (CPCV) com purga e embargo.‚úÖ M√©tricas de Otimiza√ß√£o Adequadas: Uso de AUC para classifica√ß√£o bin√°ria, ideal para problemas de trading.‚úÖ Amostragem Inteligente: Uso de amostragem estratificada para preservar a distribui√ß√£o de classes.‚úÖ Performance Garantida: Configura√ß√£o para uso mandat√≥rio de GPU.‚úÖ Logs Detalhados: Sistema de logging e gera√ß√£o de artefatos bem estruturado para auditoria.Pontos de Melhoria e Recomenda√ß√µes Estrat√©gicasThreshold de Sele√ß√£o Din√¢mico: A √∫nica cr√≠tica v√°lida da an√°lise externa. O threshold de import√¢ncia fixo (ex: 0.01) deve ser substitu√≠do por um m√©todo din√¢mico, baseado na distribui√ß√£o das import√¢ncias (ex: selecionar features acima de um certo percentil ou at√© o "cotovelo" da curva de import√¢ncia).Rastreamento de Features (catboost.Pool): Para tornar o pipeline 100% √† prova de falhas de desalinhamento, a convers√£o para NumPy deve ser substitu√≠da pelo uso do objeto catboost.Pool(data=X, label=y, feature_names=X.columns.tolist()). Isso cria um v√≠nculo expl√≠cito e seguro entre os dados e seus nomes.Estabiliza√ß√£o da Sele√ß√£o de Features: Para aumentar a robustez, implementar a "sele√ß√£o por estabilidade": treinar o CatBoost em m√∫ltiplos folds de valida√ß√£o cruzada (walk-forward) e reter apenas as features que aparecem como importantes em uma alta porcentagem (ex: >70%) dos folds.Rotulagem Avan√ßada (Triple-Barrier Method): Para alinhar ainda mais o modelo aos objetivos de trading, implementar o "M√©todo da Barreira Tripla" para rotular os dados. Este m√©todo define o alvo com base em metas de lucro (take-profit), limites de perda (stop-loss) e um tempo m√°ximo de espera, filtrando ru√≠dos de mercado e focando em movimentos significativos.

---

## Parte 4: Hist√≥rico de Experimentos e Busca por Edge Estat√≠stico

### Sess√£o de Debugging - Setembro 2025

**Problema Inicial Resolvido:** 
- ‚úÖ CatBoost estava retornando import√¢ncias uniformes (1.0) devido a problema de sincroniza√ß√£o
- ‚úÖ Solu√ß√£o: `sys.stdout.flush()` estrat√©gico em `_stage3_selectfrommodel`
- ‚úÖ Backend agora funciona corretamente em GPU

**Resultados Estat√≠sticos Atuais (Problem√°ticos):**

| Par de Moedas | R¬≤ Valida√ß√£o | R¬≤ Treino | Dataset | Features Final |
|---------------|--------------|-----------|---------|----------------|
| AUDUSD        | -0.0001      | N/A       | ~1M rows| 46 ‚Üí 18       |
| EURAUD        | +0.0001      | N/A       | ~1M rows| 46 ‚Üí 18       |
| EURCAD        | +0.0006      | 0.0071    | 1,013,430| 46 ‚Üí 18      |

**An√°lise Cr√≠tica:**
- **R¬≤ pr√≥ximo de zero** = Modelo n√£o consegue explicar vari√¢ncia do target
- **Estatisticamente sem significado** para trading
- **Infrastructure perfeita, mas sem edge detect√°vel**

### Plano de A√ß√£o para Encontrar Edge

#### 1. **Experimentos com Timeframes (PRIORIDADE ALTA)**
```yaml
# Teste diferentes janelas de predi√ß√£o
targets_to_test:
  - y_ret_fwd_5m    # Mais curto - maior ru√≠do, mas poss√≠vel edge intraday
  - y_ret_fwd_15m   # Original baseline
  - y_ret_fwd_30m   # Meio termo
  - y_ret_fwd_60m   # Atual (sem edge)
  - y_ret_fwd_240m  # 4 horas - movimentos mais estruturais
  - y_ret_fwd_1440m # 1 dia - tend√™ncias de longo prazo
```

**Hip√≥tese:** Edge pode existir em timeframes diferentes. Mercados podem ser mais previs√≠veis em:
- **5-15min:** Microestrutura e order flow
- **4h-1d:** Fundamentals e sentiment

#### 2. **Transforma√ß√£o de Target (ALTA PRIORIDADE)**
```python
# Implementar Triple-Barrier Labeling
def triple_barrier_labels(prices, target_pct=0.002, stop_pct=0.001, time_limit=60):
    """
    - target_pct: 0.2% take profit
    - stop_pct: 0.1% stop loss  
    - time_limit: 60 minutos m√°ximo
    """
    # Classifica√ß√£o: 1 (win), 0 (loss), -1 (timeout)
```

**Benef√≠cios:**
- Remove ru√≠do de pequenas flutua√ß√µes
- Foca em movimentos significativos
- Alinha com objetivos reais de trading

#### 3. **Feature Engineering Avan√ßado**
```python
# Novas categorias de features para testar
advanced_features = {
    'regime_detection': [
        'volatility_regime',  # Alto/baixo vol
        'trend_regime',       # Trending/ranging
        'correlation_regime'  # Risk-on/risk-off
    ],
    'cross_asset_signals': [
        'yield_curve_steepening',
        'carry_trade_momentum', 
        'risk_parity_flows',
        'central_bank_divergence'
    ],
    'microstructure': [
        'orderbook_imbalance_trends',
        'tick_size_effects',
        'session_transitions'  # Tokyo/London/NY overlaps
    ]
}
```

#### 4. **Per√≠odo de Dados e Regimes de Mercado**
```yaml
data_experiments:
  - period_2020_2021: "COVID regime - alta volatilidade"
  - period_2022: "Hiking cycle - regime rates"
  - period_2023: "Banking crisis - flight to quality"
  - period_2024: "AI boom - tech divergence"
  
# Teste separado por regime
regime_analysis:
  - high_vol_periods: "VIX > 25"
  - low_vol_periods: "VIX < 15"
  - rate_hiking: "Fed raising rates"
  - rate_cutting: "Fed cutting rates"
```

#### 5. **M√©tricas de Trading Espec√≠ficas**
```python
# Implementar m√©tricas al√©m de R¬≤
trading_metrics = {
    'information_coefficient': 'Correla√ß√£o rank entre predi√ß√£o e retorno',
    'directional_accuracy': 'Percentual de acertos de dire√ß√£o',
    'sharpe_ratio': 'Risk-adjusted returns',
    'max_drawdown': 'Maior perda consecutiva',
    'hit_ratio': 'Win rate',
    'profit_factor': 'Gross profit / Gross loss'
}
```

### Pr√≥ximos Experimentos Planejados

#### Experimento 1: Timeframe Sweep
- **Objetivo:** Testar todos os timeframes (5m a 1440m)
- **M√©trica:** R¬≤, IC, Directional Accuracy
- **Expectativa:** Encontrar timeframe com R¬≤ > 0.01

#### Experimento 2: Triple Barrier Implementation
- **Objetivo:** Implementar labeling baseado em take profit/stop loss
- **Configura√ß√£o:** TP=0.2%, SL=0.1%, Time=60min
- **Expectativa:** Reduzir ru√≠do, aumentar signal-to-noise ratio

#### Experimento 3: Regime-Specific Models
- **Objetivo:** Treinar modelos separados por regime de volatilidade
- **Hip√≥tese:** Diferentes regimes t√™m diferentes padr√µes preditivos
- **Implementa√ß√£o:** VIX-based splitting

#### Experimento 4: Alternative Targets
```python
alternative_targets = [
    'volatility_forecast',    # Prever volatilidade em vez de retorno
    'direction_probability',  # Probabilidade de movimento > threshold
    'momentum_persistence',   # Continua√ß√£o de tend√™ncia
    'mean_reversion_signal'   # Sinal de revers√£o
]
```

### Status Atual: Setembro 15, 2025
- ‚úÖ **Infraestrutura:** Totalmente funcional
- ‚úÖ **CatBoost:** Resolvido, produzindo import√¢ncias reais
- ‚ùå **Edge Estat√≠stico:** N√£o detectado com configura√ß√£o atual
- üîÑ **Pr√≥ximo Passo:** Experimento 1 - Timeframe Sweep

### Li√ß√µes Aprendidas
1. **Infraestrutura ‚â† Alpha:** Pipeline perfeito n√£o garante edge
2. **R¬≤ baixo √© comum:** Mercados financeiros s√£o majoritariamente aleat√≥rios
3. **Edge √© raro:** Pode estar em nichos espec√≠ficos (timeframe/regime/asset)
4. **M√∫ltiplas tentativas necess√°rias:** Processo iterativo de descoberta

---

## Como Usar os Experimentos

### Execu√ß√£o R√°pida - Busca Autom√°tica por Edge
```bash
# Executa todos os experimentos automaticamente
cd /home/horisen/projects/Pessoal/CamaleonV2/feature_selection/feature_genesis
python experiments/edge_search_orchestrator.py

# Execu√ß√£o r√°pida (vers√£o reduzida)
python experiments/edge_search_orchestrator.py --quick
```

### Experimentos Individuais

#### 1. Timeframe Sweep
```bash
# Testa diferentes janelas temporais
python experiments/timeframe_sweep.py
```

#### 2. Triple-Barrier Labeling Demo
```bash
# Demonstra rotulagem baseada em TP/SL
python experiments/triple_barrier_labeling.py
```

### Estrutura de Resultados
```
experiments/
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îî‚îÄ‚îÄ edge_search_YYYYMMDD_HHMMSS/
‚îÇ       ‚îú‚îÄ‚îÄ session_results.json          # Resultados completos
‚îÇ       ‚îú‚îÄ‚îÄ timeframe_analysis.json       # An√°lise de timeframes
‚îÇ       ‚îú‚îÄ‚îÄ barrier_optimization.json     # Otimiza√ß√£o de barreiras
‚îÇ       ‚îî‚îÄ‚îÄ recommendations.json          # Recomenda√ß√µes finais
‚îú‚îÄ‚îÄ timeframe_sweep.py                    # Experimento 1
‚îú‚îÄ‚îÄ triple_barrier_labeling.py            # Experimento 2
‚îî‚îÄ‚îÄ edge_search_orchestrator.py           # Orquestrador principal
```

### Interpreta√ß√£o de Resultados

#### M√©tricas Chave
- **R¬≤ > 0.01:** Potencial edge detectado
- **Directional Accuracy > 55%:** Capacidade preditiva significativa
- **Win Rate > 50%:** Com Triple-Barrier, indica viabilidade
- **Expected Return > 0:** Expectativa positiva de lucro

#### Sinais de Edge Promissor
```json
{
  "validation_r2": 0.025,           // R¬≤ > 2% = muito promissor
  "directional_accuracy": 0.58,     // 58% de acertos direcionais
  "win_rate": 52.3,                 // 52% win rate
  "expected_return": 0.0012,        // 0.12% retorno esperado
  "sharpe_estimate": 1.8             // Sharpe > 1.5 = boa qualidade
}
```

#### Configura√ß√µes a Implementar se Edge Encontrado
```yaml
# Exemplo de configura√ß√£o otimizada
target_optimization:
  target_column: "y_ret_fwd_240m"    # Melhor timeframe encontrado
  labeling_method: "triple_barrier"  # Use Triple-Barrier
  take_profit_pct: 0.002            # 0.2% TP
  stop_loss_pct: 0.001              # 0.1% SL
  time_limit_periods: 60            # 60 per√≠odos m√°ximo

feature_selection:
  embedded_threshold: "dynamic"      # Threshold din√¢mico
  validation_method: "cpcv"          # CPCV obrigat√≥rio
  stability_filter: true            # Filtro de estabilidade
```