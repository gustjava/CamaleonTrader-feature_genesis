# Tarefas para Revis√£o dos Logs do Pipeline

## Objetivo Geral
Eliminar numera√ß√£o por "Stage" nos logs e adotar mensagens orientadas √† funcionalidade/etapa real do processo, com padroniza√ß√£o, contexto e estrutura√ß√£o para facilitar leitura humana e an√°lise automatizada.

---

## üìã Fase 1: Infraestrutura de Logging Contextual

### Tarefa 1.1: Criar sistema de contexto de logging
- [ ] **Arquivo**: `utils/log_context.py`
  - Implementar `contextvars` para `run_id`, `task_id`, `pair`
  - Criar helper `bind_context(...)`
  - Garantir thread-safety para workers Dask

### Tarefa 1.2: Criar utilit√°rios de logging estruturado
- [ ] **Arquivo**: `utils/logging_utils.py`
  - Implementar `LoggerAdapter` que injeta `component`, `event` e contexto padr√£o
  - Criar fun√ß√µes helpers: `info_event()`, `warn_event()`, `error_event()`, `critical_event()`
  - Implementar `set_log_record_factory` para preencher chaves ausentes
  - Garantir compatibilidade com formatters existentes

### Tarefa 1.3: Atualizar configura√ß√£o de logging
- [ ] **Arquivo**: `config/logging.yaml`
  - Console: adicionar campos `%(event)s %(component)s`
  - JSON: incluir campos `event`, `component`, `run_id`, `task_id`, `pair`
  - Implementar fallback seguro para novos campos
  - Manter rota√ß√£o de logs existente

---

## üìã Fase 2: Refatora√ß√£o do Pipeline Principal

### Tarefa 2.1: Refatorar orchestration/main.py
- [ ] **Linha 335**: Remover "Dynamic Stage 0 - Pipeline Execution..." 
  - Substituir por evento `pipeline.start`
- [ ] Adicionar logs de contexto com `run_id`, `hostname`, `dashboard_url`
- [ ] Padronizar logs de sinais/encerramento com eventos `pipeline.abort`, `cluster.shutdown`
- [ ] Implementar evento `pipeline.end` e `pipeline.summary`
- [ ] Remover todas as refer√™ncias a "Stage 0" nos logs

### Tarefa 2.2: Refatorar orchestration/pipeline_orchestrator.py
- [ ] **Linha 263**: "Starting driver-side processing..." ‚Üí `task.execution.start`
- [ ] **Linha 279**: "Task i/n ..." ‚Üí `task.start` com `index`, `total`, `pair`
- [ ] Substituir separadores "====" por eventos estruturados
- [ ] Em `_log_cluster_diagnostics`: usar evento `cluster.ready` com `gpu_count`, `workers`, `dashboard_url`
- [ ] Em `discover_tasks`: usar `task.discovery.start` e `task.discovery.found`

### Tarefa 2.3: Refatorar orchestration/data_processor.py
- [ ] **Linha 275**: Remover "STAGE {order}" das mensagens
- [ ] **Linha 565**: Remover "STAGE {order}" das mensagens
- [ ] Implementar eventos `engine.start`/`engine.end` com campos:
  - `engine`, `order`, `desc`, `rows_before/after`, `cols_before/after`, `new_cols`
- [ ] Para opera√ß√µes Dask: logar `duration_ms` e eventos `io.save.*`
- [ ] Padronizar logs de persist√™ncia e wait

---

## üìã Fase 3: Refatora√ß√£o dos Engines

### Tarefa 3.1: Ajustar features/base_engine.py
- [ ] Manter logs funcionais existentes
- [ ] Substituir textos que referenciam "stage" em mensagens por nomes de opera√ß√£o
- [ ] Manter assinatura `_check_memory_usage(stage: str)` mas usar `operation_name` nos logs
- [ ] N√£o afetar chaves de DB (manter "stage" como r√≥tulo t√©cnico interno)

### Tarefa 3.2: Refatorar features/statistical_tests.py
- [ ] Substituir mensagens "Stage 3 ..." por eventos funcionais
- [ ] Implementar eventos: `engine.sampling`, `engine.wrapper_fit`, `engine.feature_selection`
- [ ] Adicionar contexto: modelo, folds, thresholds
- [ ] Manter funcionalidade, apenas mudar apresenta√ß√£o dos logs

---

## üìã Fase 4: Valida√ß√£o e Testes

### Tarefa 4.1: Testes de integra√ß√£o
- [ ] Executar pipeline com 1-2 pares pequenos
- [ ] Verificar aus√™ncia total de "Stage [0-9]" nas mensagens
- [ ] Validar logs console e arquivo JSON
- [ ] Confirmar que DB continua funcionando (schema inalterado)

### Tarefa 4.2: Valida√ß√£o de crit√©rios de aceita√ß√£o
- [ ] ‚úÖ Nenhuma mensagem de log exibe "Stage [0-9]"
- [ ] ‚úÖ Logs mostram eventos funcionais e campos contextuais consistentes
- [ ] ‚úÖ `config/logging.yaml` suporta novos campos sem quebras
- [ ] ‚úÖ Arquivo JSON tem chaves `event`, `component`, `run_id`, `task_id`, `pair`
- [ ] ‚úÖ Console fica leg√≠vel, sem "ASCII art" excessiva

---

## üìã Fase 5: Documenta√ß√£o e Limpeza

### Tarefa 5.1: Atualizar documenta√ß√£o
- [ ] Documentar nova taxonomia de eventos
- [ ] Criar guia de uso dos novos helpers de logging
- [ ] Atualizar exemplos de logs esperados

### Tarefa 5.2: Limpeza final
- [ ] Remover coment√°rios legados sobre "stages"
- [ ] Verificar consist√™ncia em todos os m√≥dulos
- [ ] Otimizar n√≠veis de log (DEBUG para detalhes, INFO conciso)

---

## üéØ Alvos Priorit√°rios (PR 1)

### Implementa√ß√£o Imediata
1. **orchestration/main.py:335** ‚Üí `pipeline.start`
2. **orchestration/pipeline_orchestrator.py:263** ‚Üí `task.execution.start`
3. **orchestration/pipeline_orchestrator.py:279** ‚Üí `task.start` com contexto
4. **orchestration/data_processor.py:275, :565** ‚Üí `engine.start`/`engine.end`
5. **features/statistical_tests.py** ‚Üí eventos funcionais

---

## ‚ö†Ô∏è Riscos e Mitiga√ß√µes

### Risco 1: Quebra de formatters
- **Mitiga√ß√£o**: Implementar `LogRecordFactory`/Filter com defaults

### Risco 2: Volume excessivo de logs
- **Mitiga√ß√£o**: Usar DEBUG para detalhes, INFO mais conciso

### Risco 3: Incompatibilidade com workers Dask
- **Mitiga√ß√£o**: Usar adapters locais e ContextVars, evitar estado global

---

## üìä Exemplo de Resultado Esperado

### Console (humano)
```
INFO  orchestration.main  pipeline.start  run_id=42 hostname=worker-01
INFO  orchestration.orchestrator  task.discovery.found  count=8 path=/data/forex
INFO  orchestration.cluster  cluster.ready  gpus=4 dashboard=http://localhost:8787
INFO  orchestration.processor  task.start  pair=EURUSD file=EURUSD_2023.parquet size_mb=512.4
INFO  features.FeatureEngineeringEngine  engine.start  pair=EURUSD order=2 desc="BK filter"
INFO  features.FeatureEngineeringEngine  engine.end    cols_before=120 cols_after=158 new_cols=38 duration_ms=8423
INFO  data_io.local_loader  io.save.end   pair=EURUSD parts=32 path=/out/EURUSD/
INFO  orchestration.processor  task.success pair=EURUSD
INFO  orchestration.main  pipeline.summary total=8 success=8 failed=0
```

### Arquivo JSON (mesmo evento, com campos extra)
```json
{"ts":"...","level":"INFO","component":"orchestration.processor","event":"task.start","run_id":42,"task_id":101,"pair":"EURUSD","filename":"EURUSD_2023.parquet","size_mb":512.4}
```

---

## üöÄ Pr√≥ximos Passos

1. **Implementar** camada de logging contextual (`utils/log_context.py`, `utils/logging_utils.py`)
2. **Atualizar** `config/logging.yaml` com novos campos
3. **Refatorar** `orchestration/main.py` e `orchestration/data_processor.py`
4. **Validar** padr√£o antes de propagar para demais m√≥dulos
5. **Testar** com pipeline completo
